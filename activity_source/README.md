# ğŸ§‘â€ğŸ’» Kafka User Event Producer

This is a Java-based Kafka producer that continuously sends randomized **user events** (like LOGIN, LOGOUT, PURCHASE, etc.) to a Kafka topic. It uses a modular design, is built with Maven, and reads configuration from a properties file.

---

## ğŸ“¦ Features

- âœ… Modular Java code (config, model, producer, util)
- ğŸ” Continuously sends events every 5 seconds
- ğŸ² Randomized user IDs and event types
- âš™ï¸ Configurable via `application.properties`
- ğŸ›  Built using Apache Kafka client & Jackson

---

## ğŸš€ Getting Started

### âœ… Prerequisites

- Java 11+
- Apache Kafka running in docker (or locally)
- Maven installed (`mvn -v`)

### ğŸ“¥ Clone the Repo

```bash
git clone git@github.com:rajatrao/flink_events_consumer.git
cd flink_events_consumer/activity_source
```

ğŸ”§ Configure Kafka Settings

Edit the src/main/resources/app.properties file:

```text
bootstrap.servers=localhost:9092
topic.name=user-events
```

Make sure the topic exists in Kafka:

- Follow `flink_app/README.md` for steps to create kafka topic

```bash
docker run --rm --network flink_app_default confluentinc/cp-kafka:7.6.0 \
kafka-topics --create --topic user-events \
--bootstrap-server kafka:29092 \
--replication-factor 1 --partitions 3
```

ğŸ›  Build & Run
ğŸ§± Compile the Project
```bash
mvn clean compile
```
â–¶ï¸ Run the Producer
```bash
mvn exec:java -Dexec.mainClass=com.event_producer.Main
```

You should see events like below as part of kafka consume event process handling
```json
{
"user_id": "589e4567-e89b-12d3-a456-426614174003",
"event_type": "LOGIN",
"event_time": 1699999999999,
"event_id": "7f34aeee-e89b-12d3-a456-426614174111",
"metadata": {
        "source": "web",
        "session_id": "abc123-e89b-12d3-a456-426614174222"
    }
}
```